{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!kaggle datasets download -d ryanmouton/ohiot1dm -p /content/drive/MyDrive/ddls_final_project/\n",
    "!unzip /content/drive/MyDrive/ddls_final_project/ohiot1dm.zip -d /content/drive/MyDrive/ddls_final_project/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Conv1D, MaxPooling1D, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_xml_data(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    events = []\n",
    "\n",
    "    for event in root.findall('.//glucose_level/event'):\n",
    "        timestamp = event.get('ts')\n",
    "        glucose_value = float(event.get('value'))\n",
    "        meal = exercise = insulin = 0\n",
    "\n",
    "        meal_event = event.find('.//meal')\n",
    "        if meal_event is not None:\n",
    "            meal = float(meal_event.get('carbs'))\n",
    "\n",
    "        exercise_event = event.find('.//exercise')\n",
    "        if exercise_event is not None:\n",
    "            exercise = float(exercise_event.get('intensity'))\n",
    "\n",
    "        insulin_event = event.find('.//insulin')\n",
    "        if insulin_event is not None:\n",
    "            insulin = float(insulin_event.get('dose'))\n",
    "\n",
    "        events.append((timestamp, glucose_value, meal, exercise, insulin))\n",
    "\n",
    "    df = pd.DataFrame(events, columns=['timestamp', 'glucose_level', 'meal', 'exercise', 'insulin'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d-%m-%Y %H:%M:%S')\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    scaler = MinMaxScaler()\n",
    "    df[['glucose_level', 'meal', 'exercise', 'insulin']] = scaler.fit_transform(df[['glucose_level', 'meal', 'exercise', 'insulin']])\n",
    "    return df, scaler\n",
    "\n",
    "def create_sequences(data, sequence_length=12):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i + sequence_length, :])\n",
    "        y.append(data[i + sequence_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model-specific Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Random Forest with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, X_val, y_val, patient, n_splits=5):\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    train_rmse, val_rmse = [], []\n",
    "\n",
    "    for train_index, val_index in kfold.split(X_train_flat):\n",
    "        X_cv_train, X_cv_val = X_train_flat[train_index], X_train_flat[val_index]\n",
    "        y_cv_train, y_cv_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        rf_model.fit(X_cv_train, y_cv_train)\n",
    "        train_pred = rf_model.predict(X_cv_train)\n",
    "        val_pred = rf_model.predict(X_cv_val)\n",
    "\n",
    "        train_rmse.append(np.sqrt(mean_squared_error(y_cv_train, train_pred)))\n",
    "        val_rmse.append(np.sqrt(mean_squared_error(y_cv_val, val_pred)))\n",
    "\n",
    "    # Plot and save cross-validation RMSE\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, n_splits + 1), train_rmse, label='Training RMSE')\n",
    "    plt.plot(range(1, n_splits + 1), val_rmse, label='Validation RMSE')\n",
    "    plt.title(f\"Random Forest Cross-Validation Training and Validation RMSE for {patient}\")\n",
    "    plt.xlabel(\"Fold\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}\", exist_ok=True)\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/random_forest_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "    rf_model.fit(X_train_flat, y_train)\n",
    "    return rf_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_xgboost(X_train, y_train, X_val, y_val, patient):\n",
    "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "    dtrain = xgb.DMatrix(X_train_flat, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val_flat, label=y_val)\n",
    "\n",
    "    params = {'objective': 'reg:squarederror', 'learning_rate': 0.1, 'max_depth': 5, 'eval_metric': 'rmse'}\n",
    "    evals_result = {}\n",
    "    evals = [(dtrain, 'train'), (dval, 'validation')]\n",
    "    xgb_model = xgb.train(params, dtrain, num_boost_round=100, evals=evals, early_stopping_rounds=10, evals_result=evals_result, verbose_eval=False)\n",
    "\n",
    "    # Plot and save XGBoost loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(evals_result['train']['rmse'], label='Training RMSE')\n",
    "    plt.plot(evals_result['validation']['rmse'], label='Validation RMSE')\n",
    "    plt.title(f\"XGBoost Training and Validation RMSE for {patient}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"RMSE\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}\", exist_ok=True)\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/xgboost_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return xgb_model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_lstm(input_shape):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(32),\n",
    "        Dropout(0.2),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def train_lstm(X_train, y_train, X_val, y_val, input_shape, patient):\n",
    "    model = build_lstm(input_shape)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Plot and save LSTM loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"LSTM Training and Validation Loss for {patient}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}\", exist_ok=True)\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/lstm_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_cnn_lstm(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(50, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def train_cnn_lstm(X_train, y_train, X_val, y_val, input_shape, patient):\n",
    "    model = build_cnn_lstm(input_shape)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Plot and save CNN-LSTM loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f\"CNN-LSTM Training and Validation Loss for {patient}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}\", exist_ok=True)\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/cnn_lstm_loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Model Evaluation with Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_type, scaler, patient, df_train, df_test):\n",
    "    # Flatten data if required by model\n",
    "    if model_type in ['random_forest', 'xgboost']:\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "    if model_type == 'xgboost':\n",
    "        dtest = xgb.DMatrix(X_test)\n",
    "        y_pred = model.predict(dtest)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "    # Rescale predictions and ground truth back to original scale\n",
    "    y_pred_rescaled = scaler.inverse_transform(np.concatenate([y_pred.reshape(-1, 1), np.zeros((len(y_pred), 3))], axis=1))[:, 0]\n",
    "    y_test_rescaled = scaler.inverse_transform(np.concatenate([y_test.reshape(-1, 1), np.zeros((len(y_test), 3))], axis=1))[:, 0]\n",
    "\n",
    "    # 1. Plot Predicted vs. Ground Truth for All Testing Data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    test_times = df_test.index[-len(y_test_rescaled):]\n",
    "    plt.plot(test_times, y_test_rescaled, label='True Glucose Levels', color='blue')\n",
    "    plt.plot(test_times, y_pred_rescaled, label='Predicted Glucose Levels', linestyle='--', color='orange')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Glucose Level (mg/dL)')\n",
    "    plt.title(f\"Predicted vs Actual Glucose Levels for {patient} ({model_type}) - Full Testing Data\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}\", exist_ok=True)\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/{model_type}_prediction_full.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Plot Past 7 Days (or available data) and Next 48 Hours\n",
    "    # Ensure the training data is sorted by timestamp to retrieve the last records accurately\n",
    "    df_train = df_train.sort_index()\n",
    "\n",
    "    # Get the last timestamp in the training data\n",
    "    last_train_timestamp = df_train.index[-1]\n",
    "\n",
    "    # Retrieve up to 7 days of data before the last timestamp\n",
    "    last_7_days_data = df_train[df_train.index >= last_train_timestamp - pd.Timedelta(days=7)]\n",
    "\n",
    "    # Extract glucose_level column and reshape for inverse transformation\n",
    "    glucose_levels_scaled = last_7_days_data[['glucose_level', 'meal', 'exercise', 'insulin']].values\n",
    "    glucose_levels_rescaled = scaler.inverse_transform(glucose_levels_scaled)[:, 0]  # Only use the glucose_level column\n",
    "\n",
    "    # Define thresholds for color coding\n",
    "    low_threshold = 70\n",
    "    high_threshold = 180\n",
    "\n",
    "    # Calculate the maximum glucose level for dynamic y-limit\n",
    "    max_glucose_level_train = np.max(glucose_levels_rescaled)  # Get max from training data\n",
    "    max_glucose_level_pred = y_pred_rescaled[:48 * 12].max()   # Get max from the first 48 hours of predictions\n",
    "    max_glucose_level = max(max_glucose_level_train, max_glucose_level_pred)\n",
    "\n",
    "    # Set ylim based on the max glucose level\n",
    "    if max_glucose_level <= 350:\n",
    "        ylim_upper = 350\n",
    "    elif max_glucose_level <= 400:\n",
    "        ylim_upper = 400\n",
    "    else:\n",
    "        ylim_upper = 450\n",
    "\n",
    "    # Plot recorded glucose levels (last 7 days) and predictions (next 48 hours)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(last_7_days_data.index, glucose_levels_rescaled, label='Recorded Glucose Levels (Last 7 Days)', color='#BFB7A8')\n",
    "\n",
    "    # Prepare time range for the next 48 hours predictions\n",
    "    prediction_times = pd.date_range(start=last_train_timestamp + pd.Timedelta(minutes=5), periods=48 * 12, freq='5T')  # 48 hours, 5-minute intervals\n",
    "    prediction_48h = y_pred_rescaled[:48 * 12]  # Limit predictions to the first 48 hours\n",
    "\n",
    "    # Plot color-coded predictions\n",
    "    plt.plot([], [], color='purple', linewidth=2.5, label='Hypoglycemia (< 70 mg/dL)')\n",
    "    plt.plot([], [], color='red', linewidth=2.5, label='Hyperglycemia (> 180 mg/dL)')\n",
    "    plt.plot([], [], color='blue', linewidth=1.5, label='Normal Range')\n",
    "\n",
    "    for i in range(len(prediction_times) - 1):\n",
    "        glucose_level = prediction_48h[i]\n",
    "        if glucose_level < low_threshold:\n",
    "            plt.plot(prediction_times[i:i + 2], prediction_48h[i:i + 2], color='purple', linewidth=2.5)\n",
    "        elif glucose_level > high_threshold:\n",
    "            plt.plot(prediction_times[i:i + 2], prediction_48h[i:i + 2], color='red', linewidth=2.5)\n",
    "        else:\n",
    "            plt.plot(prediction_times[i:i + 2], prediction_48h[i:i + 2], color='blue', linewidth=1.5)\n",
    "\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Glucose Level (mg/dL)')\n",
    "    plt.ylim(0, ylim_upper)\n",
    "    plt.title(f\"Recorded and Predicted Glucose Levels for {patient} ({model_type}) - Last 7 Days and Next 48 Hours\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    plt.savefig(f\"/content/drive/MyDrive/ddls_final_project/figures/{patient}/{model_type}_prediction_48h.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate and return metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rescaled, y_pred_rescaled))\n",
    "    mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
    "\n",
    "    return rmse, mae\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train and Evaluate Models for Each Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "patients = {\n",
    "    'patient559': {'train': '/content/drive/MyDrive/ddls_final_project/data/559-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/559-ws-testing.xml'},\n",
    "    'patient563': {'train': '/content/drive/MyDrive/ddls_final_project/data/563-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/563-ws-testing.xml'},\n",
    "    'patient570': {'train': '/content/drive/MyDrive/ddls_final_project/data/570-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/570-ws-testing.xml'},\n",
    "    'patient575': {'train': '/content/drive/MyDrive/ddls_final_project/data/575-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/575-ws-testing.xml'},\n",
    "    'patient588': {'train': '/content/drive/MyDrive/ddls_final_project/data/588-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/588-ws-testing.xml'},\n",
    "    'patient591': {'train': '/content/drive/MyDrive/ddls_final_project/data/591-ws-training.xml', 'test': '/content/drive/MyDrive/ddls_final_project/data/591-ws-testing.xml'}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for patient, files in patients.items():\n",
    "    # Load and preprocess training data\n",
    "    df_train = load_xml_data(files['train'])\n",
    "    df_train, scaler = preprocess_data(df_train)\n",
    "    X, y = create_sequences(df_train.values)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Load and preprocess testing data\n",
    "    df_test = load_xml_data(files['test'])\n",
    "    df_test.set_index('timestamp', inplace=True)\n",
    "    df_test[['glucose_level', 'meal', 'exercise', 'insulin']] = scaler.transform(df_test[['glucose_level', 'meal', 'exercise', 'insulin']])\n",
    "    X_test, y_test = create_sequences(df_test.values)\n",
    "\n",
    "    # Random Forest\n",
    "    rf_model = train_random_forest(X_train, y_train, X_val, y_val, patient)\n",
    "    rmse, mae = evaluate_model(rf_model, X_test, y_test, 'random_forest', scaler, patient, df_train, df_test)\n",
    "    results.append([patient, 'Random Forest', rmse, mae])\n",
    "\n",
    "    # XGBoost\n",
    "    xgb_model = train_xgboost(X_train, y_train, X_val, y_val, patient)\n",
    "    rmse, mae = evaluate_model(xgb_model, X_test, y_test, 'xgboost', scaler, patient, df_train, df_test)\n",
    "    results.append([patient, 'XGBoost', rmse, mae])\n",
    "\n",
    "    # LSTM\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "    lstm_model = train_lstm(X_train, y_train, X_val, y_val, input_shape, patient)\n",
    "    rmse, mae = evaluate_model(lstm_model, X_test, y_test, 'lstm', scaler, patient, df_train, df_test)\n",
    "    results.append([patient, 'LSTM', rmse, mae])\n",
    "\n",
    "    # CNN-LSTM\n",
    "    cnn_lstm_model = train_cnn_lstm(X_train, y_train, X_val, y_val, input_shape, patient)\n",
    "    rmse, mae = evaluate_model(cnn_lstm_model, X_test, y_test, 'cnn-lstm', scaler, patient, df_train, df_test)\n",
    "    results.append([patient, 'CNN-LSTM', rmse, mae])\n",
    "\n",
    "    # Save models\n",
    "    os.makedirs(f\"/content/drive/MyDrive/ddls_final_project/models/{patient}\", exist_ok=True)\n",
    "    joblib.dump(rf_model, f\"/content/drive/MyDrive/ddls_final_project/models/{patient}/random_forest_model.pkl\")\n",
    "    xgb_model.save_model(f\"/content/drive/MyDrive/ddls_final_project/models/{patient}/xgboost_model.json\")\n",
    "    lstm_model.save(f\"/content/drive/MyDrive/ddls_final_project/models/{patient}/lstm_model.h5\")\n",
    "    cnn_lstm_model.save(f\"/content/drive/MyDrive/ddls_final_project/models/{patient}/cnn_lstm_model.h5\")\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Patient', 'Model', 'RMSE', 'MAE'])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
